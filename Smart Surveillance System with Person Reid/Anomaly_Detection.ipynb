{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSx7kK0fla59",
        "outputId": "2f4a6b9c-3400-42ea-e74e-5b88343e9011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.1.41)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.8.3)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (10.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.17.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\rayan\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (5.9.8)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.2.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rayan\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\rayan\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keyboard in c:\\users\\rayan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install requests\n",
        "!pip install keyboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NEXviOwqscPX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import threading\n",
        "import requests\n",
        "import subprocess\n",
        "import keyboard\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NTYcflaQEW-"
      },
      "source": [
        "Bot Link : https://t.me/Alert_qbot\n",
        "\n",
        "To obtain user chatID :\n",
        "https://api.telegram.org/bot7031174156:AAE9_px2LX0qpsrg5zTOxWDVkB2Yiexc-9g/getupdates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 (no detections), 422.4ms\n",
            "Speed: 2.0ms preprocess, 422.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 419.1ms\n",
            "Speed: 2.0ms preprocess, 419.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 395.8ms\n",
            "Speed: 1.0ms preprocess, 395.8ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 403.4ms\n",
            "Speed: 1.6ms preprocess, 403.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 435.8ms\n",
            "Speed: 2.0ms preprocess, 435.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 459.8ms\n",
            "Speed: 2.0ms preprocess, 459.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 428.7ms\n",
            "Speed: 2.0ms preprocess, 428.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 440.7ms\n",
            "Speed: 2.0ms preprocess, 440.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 417.4ms\n",
            "Speed: 2.0ms preprocess, 417.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 406.8ms\n",
            "Speed: 1.9ms preprocess, 406.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 458.3ms\n",
            "Speed: 1.0ms preprocess, 458.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 478.8ms\n",
            "Speed: 2.0ms preprocess, 478.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 430.9ms\n",
            "Speed: 2.0ms preprocess, 430.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 391.9ms\n",
            "Speed: 2.0ms preprocess, 391.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 400.7ms\n",
            "Speed: 2.0ms preprocess, 400.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 392.6ms\n",
            "Speed: 1.5ms preprocess, 392.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 419.1ms\n",
            "Speed: 2.2ms preprocess, 419.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 404.4ms\n",
            "Speed: 2.0ms preprocess, 404.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 393.2ms\n",
            "Speed: 1.6ms preprocess, 393.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 406.5ms\n",
            "Speed: 3.0ms preprocess, 406.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 fires, 393.4ms\n",
            "Speed: 2.0ms preprocess, 393.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 388.0ms\n",
            "Speed: 2.0ms preprocess, 388.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 394.5ms\n",
            "Speed: 2.0ms preprocess, 394.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 fires, 397.4ms\n",
            "Speed: 2.1ms preprocess, 397.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 fires, 388.1ms\n",
            "Speed: 2.0ms preprocess, 388.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 fires, 415.6ms\n",
            "Speed: 2.0ms preprocess, 415.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 415.3ms\n",
            "Speed: 2.0ms preprocess, 415.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 409.1ms\n",
            "Speed: 2.0ms preprocess, 409.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 401.7ms\n",
            "Speed: 1.0ms preprocess, 401.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 401.9ms\n",
            "Speed: 2.2ms preprocess, 401.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 418.8ms\n",
            "Speed: 1.0ms preprocess, 418.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 410.5ms\n",
            "Speed: 2.0ms preprocess, 410.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 392.7ms\n",
            "Speed: 2.0ms preprocess, 392.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 392.9ms\n",
            "Speed: 3.3ms preprocess, 392.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 379.5ms\n",
            "Speed: 2.0ms preprocess, 379.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 384.3ms\n",
            "Speed: 2.0ms preprocess, 384.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 380.2ms\n",
            "Speed: 2.0ms preprocess, 380.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 393.0ms\n",
            "Speed: 1.9ms preprocess, 393.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 388.0ms\n",
            "Speed: 1.0ms preprocess, 388.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 403.9ms\n",
            "Speed: 2.0ms preprocess, 403.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 391.5ms\n",
            "Speed: 1.0ms preprocess, 391.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 385.2ms\n",
            "Speed: 2.0ms preprocess, 385.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 382.1ms\n",
            "Speed: 2.0ms preprocess, 382.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 387.9ms\n",
            "Speed: 2.0ms preprocess, 387.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 404.0ms\n",
            "Speed: 2.0ms preprocess, 404.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 383.1ms\n",
            "Speed: 2.0ms preprocess, 383.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 386.5ms\n",
            "Speed: 2.0ms preprocess, 386.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 377.9ms\n",
            "Speed: 2.0ms preprocess, 377.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 377.4ms\n",
            "Speed: 2.0ms preprocess, 377.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 398.2ms\n",
            "Speed: 1.0ms preprocess, 398.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 374.9ms\n",
            "Speed: 2.0ms preprocess, 374.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 387.7ms\n",
            "Speed: 1.0ms preprocess, 387.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 384.4ms\n",
            "Speed: 1.0ms preprocess, 384.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 389.3ms\n",
            "Speed: 1.0ms preprocess, 389.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 394.2ms\n",
            "Speed: 1.0ms preprocess, 394.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 382.0ms\n",
            "Speed: 1.0ms preprocess, 382.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 391.5ms\n",
            "Speed: 1.0ms preprocess, 391.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 389.4ms\n",
            "Speed: 2.0ms preprocess, 389.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 390.5ms\n",
            "Speed: 1.0ms preprocess, 390.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 400.6ms\n",
            "Speed: 1.0ms preprocess, 400.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 393.3ms\n",
            "Speed: 1.0ms preprocess, 393.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 410.1ms\n",
            "Speed: 2.0ms preprocess, 410.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 411.2ms\n",
            "Speed: 1.0ms preprocess, 411.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 391.0ms\n",
            "Speed: 2.0ms preprocess, 391.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 457.9ms\n",
            "Speed: 2.0ms preprocess, 457.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 409.7ms\n",
            "Speed: 1.0ms preprocess, 409.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 417.6ms\n",
            "Speed: 1.0ms preprocess, 417.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 468.4ms\n",
            "Speed: 2.0ms preprocess, 468.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 412.5ms\n",
            "Speed: 1.3ms preprocess, 412.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 400.2ms\n",
            "Speed: 2.0ms preprocess, 400.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 387.8ms\n",
            "Speed: 1.6ms preprocess, 387.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 399.1ms\n",
            "Speed: 2.0ms preprocess, 399.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 407.3ms\n",
            "Speed: 2.0ms preprocess, 407.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 388.9ms\n",
            "Speed: 2.8ms preprocess, 388.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 415.0ms\n",
            "Speed: 1.0ms preprocess, 415.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 379.0ms\n",
            "Speed: 1.6ms preprocess, 379.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 411.0ms\n",
            "Speed: 2.0ms preprocess, 411.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 437.9ms\n",
            "Speed: 2.0ms preprocess, 437.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 369.3ms\n",
            "Speed: 11.6ms preprocess, 369.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 347.8ms\n",
            "Speed: 1.0ms preprocess, 347.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 386.0ms\n",
            "Speed: 1.0ms preprocess, 386.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 407.1ms\n",
            "Speed: 1.0ms preprocess, 407.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 393.1ms\n",
            "Speed: 1.0ms preprocess, 393.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 422.0ms\n",
            "Speed: 2.0ms preprocess, 422.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 372.5ms\n",
            "Speed: 2.0ms preprocess, 372.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 373.4ms\n",
            "Speed: 1.0ms preprocess, 373.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 360.6ms\n",
            "Speed: 1.0ms preprocess, 360.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 370.9ms\n",
            "Speed: 1.0ms preprocess, 370.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 373.1ms\n",
            "Speed: 1.0ms preprocess, 373.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 359.1ms\n",
            "Speed: 1.0ms preprocess, 359.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 369.6ms\n",
            "Speed: 1.0ms preprocess, 369.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 375.3ms\n",
            "Speed: 1.0ms preprocess, 375.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 416.8ms\n",
            "Speed: 1.0ms preprocess, 416.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 433.5ms\n",
            "Speed: 1.0ms preprocess, 433.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 415.9ms\n",
            "Speed: 2.0ms preprocess, 415.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 422.4ms\n",
            "Speed: 2.1ms preprocess, 422.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 468.3ms\n",
            "Speed: 1.0ms preprocess, 468.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 412.2ms\n",
            "Speed: 1.0ms preprocess, 412.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 403.7ms\n",
            "Speed: 1.0ms preprocess, 403.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 412.8ms\n",
            "Speed: 2.0ms preprocess, 412.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 402.8ms\n",
            "Speed: 2.0ms preprocess, 402.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 402.6ms\n",
            "Speed: 2.0ms preprocess, 402.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 414.4ms\n",
            "Speed: 2.0ms preprocess, 414.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 417.1ms\n",
            "Speed: 2.0ms preprocess, 417.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 (no detections), 404.7ms\n",
            "Speed: 1.5ms preprocess, 404.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 414.2ms\n",
            "Speed: 1.0ms preprocess, 414.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 408.7ms\n",
            "Speed: 1.0ms preprocess, 408.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 403.8ms\n",
            "Speed: 2.1ms preprocess, 403.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 405.1ms\n",
            "Speed: 2.0ms preprocess, 405.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 394.0ms\n",
            "Speed: 2.0ms preprocess, 394.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 480.7ms\n",
            "Speed: 2.0ms preprocess, 480.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 407.0ms\n",
            "Speed: 2.0ms preprocess, 407.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 423.7ms\n",
            "Speed: 2.0ms preprocess, 423.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 436.3ms\n",
            "Speed: 2.0ms preprocess, 436.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 (no detections), 439.0ms\n",
            "Speed: 2.0ms preprocess, 439.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 408.8ms\n",
            "Speed: 2.0ms preprocess, 408.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 422.0ms\n",
            "Speed: 2.0ms preprocess, 422.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 413.8ms\n",
            "Speed: 1.0ms preprocess, 413.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 410.2ms\n",
            "Speed: 2.6ms preprocess, 410.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 391.8ms\n",
            "Speed: 2.0ms preprocess, 391.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 417.4ms\n",
            "Speed: 2.0ms preprocess, 417.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 422.6ms\n",
            "Speed: 2.0ms preprocess, 422.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 396.2ms\n",
            "Speed: 1.0ms preprocess, 396.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "Fire\n",
            "\n",
            "0: 480x640 (no detections), 408.1ms\n",
            "Speed: 1.0ms preprocess, 408.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 fires, 417.1ms\n",
            "Speed: 2.0ms preprocess, 417.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "Fire\n",
            "\n",
            "0: 480x640 (no detections), 384.9ms\n",
            "Speed: 1.0ms preprocess, 384.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 412.3ms\n",
            "Speed: 2.0ms preprocess, 412.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 403.3ms\n",
            "Speed: 1.0ms preprocess, 403.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 413.5ms\n",
            "Speed: 1.0ms preprocess, 413.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 395.5ms\n",
            "Speed: 1.0ms preprocess, 395.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 392.7ms\n",
            "Speed: 1.0ms preprocess, 392.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 393.5ms\n",
            "Speed: 1.0ms preprocess, 393.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 383.8ms\n",
            "Speed: 2.0ms preprocess, 383.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 394.2ms\n",
            "Speed: 1.0ms preprocess, 394.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 386.6ms\n",
            "Speed: 2.0ms preprocess, 386.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 368.2ms\n",
            "Speed: 2.0ms preprocess, 368.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 433.4ms\n",
            "Speed: 2.0ms preprocess, 433.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 436.4ms\n",
            "Speed: 1.0ms preprocess, 436.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 487.8ms\n",
            "Speed: 2.0ms preprocess, 487.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 364.2ms\n",
            "Speed: 3.1ms preprocess, 364.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 363.7ms\n",
            "Speed: 2.0ms preprocess, 363.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 380.2ms\n",
            "Speed: 1.0ms preprocess, 380.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 374.8ms\n",
            "Speed: 2.0ms preprocess, 374.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 368.3ms\n",
            "Speed: 1.0ms preprocess, 368.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 384.0ms\n",
            "Speed: 1.0ms preprocess, 384.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 373.7ms\n",
            "Speed: 3.0ms preprocess, 373.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 360.0ms\n",
            "Speed: 1.0ms preprocess, 360.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 374.2ms\n",
            "Speed: 2.0ms preprocess, 374.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 364.3ms\n",
            "Speed: 1.8ms preprocess, 364.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 360.7ms\n",
            "Speed: 1.0ms preprocess, 360.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 384.0ms\n",
            "Speed: 1.0ms preprocess, 384.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 351.1ms\n",
            "Speed: 1.0ms preprocess, 351.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 399.4ms\n",
            "Speed: 1.0ms preprocess, 399.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 448.4ms\n",
            "Speed: 1.0ms preprocess, 448.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 391.6ms\n",
            "Speed: 2.0ms preprocess, 391.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 334.2ms\n",
            "Speed: 1.0ms preprocess, 334.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fire\n",
            "\n",
            "0: 480x640 1 fire, 352.4ms\n",
            "Speed: 1.0ms preprocess, 352.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fire, 445.9ms\n",
            "Speed: 1.0ms preprocess, 445.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 492.2ms\n",
            "Speed: 1.0ms preprocess, 492.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 446.8ms\n",
            "Speed: 1.5ms preprocess, 446.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 428.5ms\n",
            "Speed: 2.0ms preprocess, 428.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 456.6ms\n",
            "Speed: 1.0ms preprocess, 456.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 470.4ms\n",
            "Speed: 3.0ms preprocess, 470.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 478.9ms\n",
            "Speed: 2.0ms preprocess, 478.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 459.5ms\n",
            "Speed: 1.0ms preprocess, 459.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 441.2ms\n",
            "Speed: 1.5ms preprocess, 441.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 448.2ms\n",
            "Speed: 1.0ms preprocess, 448.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 477.5ms\n",
            "Speed: 2.0ms preprocess, 477.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 450.3ms\n",
            "Speed: 2.0ms preprocess, 450.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 471.9ms\n",
            "Speed: 2.0ms preprocess, 471.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 489.8ms\n",
            "Speed: 3.0ms preprocess, 489.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 419.1ms\n",
            "Speed: 2.0ms preprocess, 419.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 410.1ms\n",
            "Speed: 1.0ms preprocess, 410.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 408.1ms\n",
            "Speed: 2.0ms preprocess, 408.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 397.6ms\n",
            "Speed: 0.9ms preprocess, 397.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 392.2ms\n",
            "Speed: 2.0ms preprocess, 392.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 378.3ms\n",
            "Speed: 2.0ms preprocess, 378.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 397.0ms\n",
            "Speed: 1.7ms preprocess, 397.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 408.1ms\n",
            "Speed: 1.0ms preprocess, 408.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 407.1ms\n",
            "Speed: 2.0ms preprocess, 407.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 405.5ms\n",
            "Speed: 2.0ms preprocess, 405.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 410.0ms\n",
            "Speed: 2.0ms preprocess, 410.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 fight, 404.1ms\n",
            "Speed: 2.0ms preprocess, 404.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Fight\n",
            "\n",
            "0: 480x640 (no detections), 411.9ms\n",
            "Speed: 16.3ms preprocess, 411.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 414.7ms\n",
            "Speed: 1.0ms preprocess, 414.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 396.9ms\n",
            "Speed: 1.0ms preprocess, 396.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 402.8ms\n",
            "Speed: 2.0ms preprocess, 402.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 390.7ms\n",
            "Speed: 2.3ms preprocess, 390.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 393.3ms\n",
            "Speed: 1.0ms preprocess, 393.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 401.2ms\n",
            "Speed: 1.0ms preprocess, 401.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 389.9ms\n",
            "Speed: 2.0ms preprocess, 389.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 407.1ms\n",
            "Speed: 2.0ms preprocess, 407.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 417.4ms\n",
            "Speed: 2.0ms preprocess, 417.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 390.8ms\n",
            "Speed: 2.0ms preprocess, 390.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 408.9ms\n",
            "Speed: 2.0ms preprocess, 408.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 425.2ms\n",
            "Speed: 1.0ms preprocess, 425.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 411.8ms\n",
            "Speed: 2.0ms preprocess, 411.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 424.1ms\n",
            "Speed: 2.0ms preprocess, 424.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 444.6ms\n",
            "Speed: 2.0ms preprocess, 444.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 400.3ms\n",
            "Speed: 1.0ms preprocess, 400.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 401.5ms\n",
            "Speed: 1.0ms preprocess, 401.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 398.9ms\n",
            "Speed: 1.0ms preprocess, 398.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 387.3ms\n",
            "Speed: 1.0ms preprocess, 387.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 383.0ms\n",
            "Speed: 1.0ms preprocess, 383.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 403.2ms\n",
            "Speed: 2.0ms preprocess, 403.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 392.8ms\n",
            "Speed: 2.0ms preprocess, 392.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 390.1ms\n",
            "Speed: 1.0ms preprocess, 390.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 385.2ms\n",
            "Speed: 1.0ms preprocess, 385.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 380.0ms\n",
            "Speed: 1.0ms preprocess, 380.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class AnomalyDetection:\n",
        "    def __init__(self, capture_source, camera_name):\n",
        "        self.capture_source = capture_source\n",
        "        self.camera_name = camera_name\n",
        "        self.msg_sent = False\n",
        "        self.frames=[]\n",
        "        self.no_detct = 0\n",
        "        i=-1\n",
        "        # Device info\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # Model info\n",
        "        self.model = YOLO(r\"C:\\Users\\rayan\\OneDrive\\Documents\\Argus\\model.pt\")\n",
        "\n",
        "    def send_msg(self, msg):\n",
        "        print(msg)\n",
        "\n",
        "    def frames_to_video(self, out_path, fps=2):\n",
        "    # Determine the shape of the frames\n",
        "        size = (self.frames[0].shape[1], self.frames[0].shape[0])\n",
        "        # Define the codec and create VideoWriter object\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Choose the codec (here, MP4V)\n",
        "        out = cv2.VideoWriter(out_path, fourcc, fps, size)\n",
        "\n",
        "        # Write each frame to the video\n",
        "        for frame in self.frames:\n",
        "            out.write(frame)\n",
        "\n",
        "        # Release the VideoWriter object\n",
        "        out.release()\n",
        "        print(f\"Video saved to: {out_path}\")\n",
        "\n",
        "\n",
        "    def predict(self, im0):\n",
        "        clss = []\n",
        "        class_labels = {0: \"Accident\", 1: \"Fight\", 2: \"Fire\", 3: \"Smoke\"}\n",
        "        results = self.model.predict(source=im0, conf=0.6)\n",
        "\n",
        "        for r in results:\n",
        "            clss = r.boxes.cls.cpu().numpy().astype(int)\n",
        "            if len(clss) > 0:\n",
        "                self.no_detct = 0\n",
        "                self.frames.append(im0)\n",
        "                if not self.msg_sent:\n",
        "                    for cl in clss:\n",
        "                        self.send_msg(class_labels[cl])\n",
        "                    self.msg_sent = True\n",
        "            else:\n",
        "                self.no_detct += 1\n",
        "                self.msg_sent = False\n",
        "\n",
        "        if self.no_detct > 10 and len(self.frames) > 0:\n",
        "            self.no_detct = 0\n",
        "            current_datetime = datetime.datetime.now().strftime(r\"%Y-%m-%d\\%H-%M-%S\")\n",
        "            out_path = \"C:/Users/rayan/OneDrive/Documents/Argus/please.txt\"\n",
        "            with open(out_path, \"a\") as f:\n",
        "                f.write(f\"Camera 1 {current_datetime} {','.join(class_labels[cl] for cl in clss) or 'No anomaly detected'}\\n\")\n",
        "\n",
        "    def call(self):\n",
        "        cap = cv2.VideoCapture(self.capture_source)\n",
        "        assert cap.isOpened()\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
        "        while True:\n",
        "            ret, im0 = cap.read()\n",
        "            assert ret\n",
        "            self.predict(im0)\n",
        "            #cv2.imshow(f'{self.camera_name} - Anomaly Detection', im0)\n",
        "            if cv2.waitKey(5) & 0xFF == 27 or keyboard.is_pressed('esc'):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Instantiate anomaly detection for each camera\n",
        "detector1 = AnomalyDetection(capture_source=0, camera_name='Camera 1')\n",
        "#detector2 = AnomalyDetection(capture_source='http://192.168.63.251:8080/video', camera_name='Camera 2')\n",
        "\n",
        "# Start anomaly detection for each camera in separate threads\n",
        "thread1 = threading.Thread(target=detector1.call)\n",
        "#thread2 = threading.Thread(target=detector2.call)\n",
        "\n",
        "# Start both threads\n",
        "thread1.start()\n",
        "#thread2.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "thread1.join()\n",
        "#thread2.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Instantiate anomaly detection for each camera\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m detector1 \u001b[38;5;241m=\u001b[39m \u001b[43mAnomalyDetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapture_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://192.168.63.52:8080/video\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCamera 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m detector2 \u001b[38;5;241m=\u001b[39m AnomalyDetection(capture_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://192.168.63.251:8080/video\u001b[39m\u001b[38;5;124m'\u001b[39m, camera_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCamera 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Start anomaly detection for each camera in separate threads\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mAnomalyDetection.__init__\u001b[1;34m(self, capture_source, camera_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Model info\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:240\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    237\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\nn\\tasks.py:806\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\nn\\tasks.py:732\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    726\u001b[0m         {\n\u001b[0;32m    727\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    730\u001b[0m         }\n\u001b[0;32m    731\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.pt'"
          ]
        }
      ],
      "source": [
        "class AnomalyDetection:\n",
        "    def __init__(self, capture_source, camera_name):\n",
        "        self.capture_source = capture_source\n",
        "        self.camera_name = camera_name\n",
        "        self.msg_sent = False\n",
        "        # Device info\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # Model info\n",
        "        self.model = YOLO('best.pt')  \n",
        "    \n",
        "    def send_msg(self, msg):\n",
        "        subprocess.call(['cscript', 'popup.vbs', f\"{self.camera_name} - Anomaly Detected: {msg}\"], shell=True)\n",
        "    \n",
        "    def predict(self, im0):\n",
        "        #class_ids = 0\n",
        "        clss=[]\n",
        "        results = self.model.predict(source=im0, conf=0.4)\n",
        "        anomaly = [\"Accident\", \"Fight\", \"Fire\", \"Smoke\"]\n",
        "        for r in results:\n",
        "            clss = r.boxes.cls.cpu().numpy().astype(int)\n",
        "            #if len(clss) > 0:\n",
        "                #class_ids += 1\n",
        "        if len(clss)>0:\n",
        "            if not self.msg_sent:\n",
        "                for cl in clss:\n",
        "                    self.send_msg(anomaly[cl])\n",
        "                self.msg_sent = True\n",
        "        else:\n",
        "            self.msg_sent = False\n",
        "            \n",
        "    def __call__(self):\n",
        "        cap = cv2.VideoCapture(self.capture_source)\n",
        "        assert cap.isOpened()\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
        "        while True:\n",
        "            ret, im0 = cap.read()\n",
        "            assert ret\n",
        "            self.predict(im0)\n",
        "            #cv2.imshow(f'{self.camera_name} - Anomaly Detection', im0)\n",
        "            if cv2.waitKey(5) & 0xFF == 27 or keyboard.is_pressed('esc'):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Instantiate anomaly detection for each camera\n",
        "detector1 = AnomalyDetection(capture_source='http://192.168.63.52:8080/video', camera_name='Camera 1')\n",
        "detector2 = AnomalyDetection(capture_source='http://192.168.63.251:8080/video', camera_name='Camera 2')\n",
        "\n",
        "# Start anomaly detection for each camera in separate threads\n",
        "thread1 = threading.Thread(target=detector1.__call__)\n",
        "thread2 = threading.Thread(target=detector2.__call__)\n",
        "\n",
        "# Start both threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "thread1.join()\n",
        "thread2.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AnomalyDetection:\n",
        "    def __init__(self, capture_source):\n",
        "        self.capture_source = capture_source\n",
        "        self.msg_sent = False\n",
        "        # Device info\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # Model info\n",
        "        self.model = YOLO('best.pt') \n",
        "        #out = cv2.VideoWriter(r'C:\\Users\\lenovo\\Downloads\\Anomaly detection\\Detection', cv2.VideoWriter_fourcc(*'XVID'), fps, frame_size) \n",
        "    \n",
        "    def predict(self, im0):\n",
        "        #class_ids = 0\n",
        "        results = self.model.predict(source=im0, conf=0.2,save=True)\n",
        "        anomaly = [\"Accident\", \"Fight\", \"Fire\", \"Smoke\"]\n",
        "        for r in results:\n",
        "            clss = r.boxes.cls.cpu().numpy().astype(int)\n",
        "            #out.write(im0)\n",
        "        if len(clss)>0:\n",
        "            if not self.msg_sent:\n",
        "                for cl in clss:\n",
        "                    print(cl)\n",
        "                self.msg_sent = True\n",
        "        else:\n",
        "            self.msg_sent = False\n",
        "            \n",
        "    def __call__(self):\n",
        "        cap = cv2.VideoCapture(self.capture_source)\n",
        "        assert cap.isOpened()\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
        "        # # Obtain frames per second (fps)\n",
        "        # fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        # # Obtain frame size\n",
        "        # frame_size = (cv2.CAP_PROP_FRAME_WIDTH,cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "        while True:\n",
        "            ret, im0 = cap.read()\n",
        "            assert ret\n",
        "            self.predict(im0)\n",
        "            cv2.imshow('Anomaly Detection', im0)\n",
        "            if cv2.waitKey(5) & 0xFF == 27 or keyboard.is_pressed('esc'):\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "detector = AnomalyDetection(capture_source=0)\n",
        "detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "##################################################################################################################################################################################################################################\n",
        "\n",
        "class ObjectDetection:\n",
        "    def __init__(self):\n",
        "        # default parameters\n",
        "       # self.capture_index = capture_index\n",
        "        self.msg_sent = False\n",
        "        count=1\n",
        "        # model information\n",
        "        self.model = self.load_model()\n",
        "        # device information\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        \n",
        "    def load_model(self):\n",
        "        model=YOLO(r\"C:\\Users\\lenovo\\Downloads\\Anomaly detection\\best.pt\")\n",
        "        model.fuse()\n",
        "        return model    \n",
        "\n",
        "    def predict(self, im0):\n",
        "        results = self.model(im0)\n",
        "        return results\n",
        "\n",
        "    def plot_bboxes(self, results, im0):\n",
        "        class_ids = []\n",
        "        for r in results:\n",
        "          clss = r.boxes.cls.cpu().numpy()\n",
        "        return im0, clss, class_ids\n",
        "            \n",
        "    def __call__(self):\n",
        "        #cap = cv2.VideoCapture(self.capture_index)\n",
        "        cap=cv2.VideoCapture('http://192.168.63.52:8080/video')\n",
        "        assert cap.isOpened()\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
        "        frame_count = 0\n",
        "        while True:\n",
        "            self.start_time = time()\n",
        "            ret, im0 = cap.read()\n",
        "            assert ret\n",
        "            frame_count=frame_count+1\n",
        "            if frame_count==6:\n",
        "              results = self.predict(im0)\n",
        "              im0, clss, class_ids = self.plot_bboxes(results, im0)\n",
        "\n",
        "              # Only send alert If not sent before\n",
        "              if len(class_ids) > 0:\n",
        "                  if not self.msg_sent:\n",
        "                      cv2.imwrite(f\"C:/Users/lenovo/Downloads/Anomaly detection/Detection/anomaly_{count}.jpg\",im0)\n",
        "                      count=count+1\n",
        "                      #send_msg(im0 , clss)\n",
        "                      self.msg_sent = True\n",
        "              else:\n",
        "                  self.msg_sent = False\n",
        "              frame_count=0\n",
        "\n",
        "            cv2.imshow('Anomaly Detection', im0)\n",
        "            if cv2.waitKey(5) & 0xFF == 27:\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        server.quit()\n",
        "\n",
        "detector = ObjectDetection()\n",
        "detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load pre-trained face detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Function to detect faces and extract features\n",
        "def detect_and_extract_features(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Detect faces in the frame\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    \n",
        "    # Extract features from detected faces\n",
        "    keypoints_list = []\n",
        "    descriptors_list = []\n",
        "    faces_coordinates = []\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Draw bounding box around the face\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        faces_coordinates.append((x, y, w, h))\n",
        "        \n",
        "        # Extract face region\n",
        "        face_roi = gray[y:y+h, x:x+w]\n",
        "        \n",
        "        # Initialize ORB feature descriptor\n",
        "        orb = cv2.ORB_create()\n",
        "        \n",
        "        # Detect keypoints and compute descriptors\n",
        "        kp, des = orb.detectAndCompute(face_roi, None)\n",
        "        keypoints_list.append(kp)\n",
        "        descriptors_list.append(des)\n",
        "    \n",
        "    return keypoints_list, descriptors_list, faces_coordinates\n",
        "\n",
        "# Function to match features between two sets of descriptors\n",
        "def match_features(descriptors1, descriptors2):\n",
        "    if descriptors1 is None or descriptors2 is None:\n",
        "        return []\n",
        "    \n",
        "    # Initialize brute force matcher\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    \n",
        "    # Match descriptors\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "    \n",
        "    # Sort matches based on distance\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "    \n",
        "    return matches\n",
        "\n",
        "# Function to display matched faces\n",
        "def display_matched_faces(frame1, frame2, keypoints1, keypoints2, matches, faces1, faces2):\n",
        "    # Draw bounding boxes around detected faces\n",
        "    for (x, y, w, h) in faces1:\n",
        "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    for (x, y, w, h) in faces2:\n",
        "        cv2.rectangle(frame2, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    \n",
        "    # Draw matches on the frames\n",
        "    matched_image = cv2.drawMatches(frame1, keypoints1, frame2, keypoints2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "    \n",
        "    # Display matched faces\n",
        "    cv2_imshow(matched_image)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the videos\n",
        "    video_path1 = '/content/1.mp4'\n",
        "    video_path2 = '/content/2.mp4'\n",
        "\n",
        "    # Open the videos\n",
        "    cap1 = cv2.VideoCapture(video_path1)\n",
        "    cap2 = cv2.VideoCapture(video_path2)\n",
        "\n",
        "    # Read the frames of each video\n",
        "    frame1_list = []\n",
        "    frame2_list = []\n",
        "    while True:\n",
        "        ret1, frame1 = cap1.read()\n",
        "        ret2, frame2 = cap2.read()\n",
        "        \n",
        "        if not ret1 or not ret2:\n",
        "            break\n",
        "        \n",
        "        frame1_list.append(frame1)\n",
        "        frame2_list.append(frame2)\n",
        "\n",
        "    # Detect and extract features from the frames of each video\n",
        "    keypoints1_list, descriptors1_list, faces1_list = [], [], []\n",
        "    keypoints2_list, descriptors2_list, faces2_list = [], [], []\n",
        "    for frame1, frame2 in zip(frame1_list, frame2_list):\n",
        "        keypoints1, descriptors1, faces1 = detect_and_extract_features(frame1)\n",
        "        keypoints2, descriptors2, faces2 = detect_and_extract_features(frame2)\n",
        "        \n",
        "        keypoints1_list.append(keypoints1)\n",
        "        descriptors1_list.append(descriptors1)\n",
        "        faces1_list.append(faces1)\n",
        "        \n",
        "        keypoints2_list.append(keypoints2)\n",
        "        descriptors2_list.append(descriptors2)\n",
        "        faces2_list.append(faces2)\n",
        "\n",
        "    # Match features between the frames of the two videos\n",
        "    matches_list = []\n",
        "    for descriptors1, descriptors2 in zip(descriptors1_list, descriptors2_list):\n",
        "        matches = match_features(descriptors1[0] if descriptors1 else None, descriptors2[0] if descriptors2 else None)\n",
        "        matches_list.append(matches)\n",
        "\n",
        "    # Display matched faces for each pair of frames\n",
        "    for frame1, frame2, keypoints1, keypoints2, matches, faces1, faces2 in zip(frame1_list, frame2_list, keypoints1_list, keypoints2_list, matches_list, faces1_list, faces2_list):\n",
        "        display_matched_faces(frame1.copy(), frame2.copy(), keypoints1[0] if keypoints1 else None, keypoints2[0] if keypoints2 else None, matches, faces1, faces2)\n",
        "\n",
        "    # Release the video capture objects\n",
        "    cap1.release()\n",
        "    cap2.release()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f939dc046ae95b61db57b1ddfb635e5199eac9f7bf30422bfd106b8f44dc254"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
