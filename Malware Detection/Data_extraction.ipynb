{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ClrOk4HN9mlx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://ember.elastic.co/ember_dataset_2017_2.tar.bz2'\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "with open('ember_dataset_2017_2.tar.bz2', 'wb') as file:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import bz2\n",
        "\n",
        "# Decompress and extract the tar.bz2 file\n",
        "with bz2.open('ember_dataset_2017_2.tar.bz2', 'rb') as f_in, tarfile.open(fileobj=f_in, mode='r') as tar:\n",
        "    tar.extractall()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzF2pIrbFAWw",
        "outputId": "2c5c0694-2a83-4576-f593-2de1d7b5cd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mshee\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "x ember_2017_2/\n",
            "x ember_2017_2/train_features_1.jsonl\n",
            "x ember_2017_2/train_features_0.jsonl\n",
            "x ember_2017_2/train_features_3.jsonl\n",
            "x ember_2017_2/test_features.jsonl\n",
            "x ember_2017_2/train_features_5.jsonl\n",
            "x ember_2017_2/train_features_4.jsonl\n",
            "x ember_2017_2/train_features_2.jsonl\n"
          ]
        }
      ],
      "source": [
        "#extracting the decompressed file\n",
        "%cd C:\\project\n",
        "!tar -xvf ember_dataset_2017_2.tar.bz2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "PgqJNHtUG2Y0",
        "outputId": "eb65a2c4-90d5-4a4c-9306-f0b23ec23efb"
      },
      "outputs": [],
      "source": [
        "#vectorization\n",
        "import ember\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "Vectorizing training set\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900000/900000 [10:46<00:00, 1392.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizing test set\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [02:40<00:00, 1248.21it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099995</th>\n",
              "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099996</th>\n",
              "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099997</th>\n",
              "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099998</th>\n",
              "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099999</th>\n",
              "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    sha256 appeared  label  \\\n",
              "0        0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0   \n",
              "1        d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12      0   \n",
              "2        c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0   \n",
              "3        7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0   \n",
              "4        ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0   \n",
              "...                                                    ...      ...    ...   \n",
              "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  2017-12      0   \n",
              "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  2017-12      1   \n",
              "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  2017-12      0   \n",
              "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  2017-12      1   \n",
              "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  2017-12      1   \n",
              "\n",
              "        subset  \n",
              "0        train  \n",
              "1        train  \n",
              "2        train  \n",
              "3        train  \n",
              "4        train  \n",
              "...        ...  \n",
              "1099995   test  \n",
              "1099996   test  \n",
              "1099997   test  \n",
              "1099998   test  \n",
              "1099999   test  \n",
              "\n",
              "[1100000 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ember.create_vectorized_features(\"C:\\Users\\mshee\\OneDrive\\Desktop\\proo\\ember_2017_2\")\n",
        "ember.create_metadata(\"C:\\Users\\mshee\\OneDrive\\Desktop\\proo\\ember_2017_2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JcEJoz7wJINc",
        "outputId": "b6cf32cc-2d54-421d-d793-5fda3b1e597f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sha256 appeared  label subset\n",
              "0  0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0  train\n",
              "1  d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12      0  train\n",
              "2  c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0  train\n",
              "3  7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0  train\n",
              "4  ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0  train"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ember\n",
        "data_path = 'C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\ember_2017_2'\n",
        "emberdf = ember.read_metadata(data_path)\n",
        "emberdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZGflSEX279",
        "outputId": "389163c5-98d5-4c3e-b6cb-5288cc99557a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ]
        }
      ],
      "source": [
        "X_train0, y_train0, X_test0, y_test0 = ember.read_vectorized_features(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ6pgy_4X98N",
        "outputId": "480e1fff-bcf3-4671-d9fc-5cfa10eb2f46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "memmap([[1.4676122e-02, 4.2218715e-03, 3.9226813e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [7.2290748e-02, 1.4057922e-02, 1.1037279e-02, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [1.8452372e-01, 3.1307504e-02, 5.6928140e-03, ..., 4.4229600e+05,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        ...,\n",
              "        [3.2558188e-01, 5.2042645e-03, 4.0974934e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [5.0731432e-01, 9.9041909e-03, 5.1698429e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [6.8576080e-01, 4.2310823e-03, 4.0683481e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00]], dtype=float32)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49pnDe3OYBIb",
        "outputId": "e28c54f9-1648-47dd-819f-8b270b97ea35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((900000, 2381), (900000,), (200000, 2381), (200000,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#shape of the dataset\n",
        "X_train0.shape, y_train0.shape, X_test0.shape, y_test0.shape\n",
        "#Training set: 900,000 samples, each with 2381 features.\n",
        "#Training labels: 900,000 labels.\n",
        "#Test set: 200,000 samples, each with 2381 features.\n",
        "#Test labels: 200,000 labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHlJOCxHYL-f",
        "outputId": "2f43e688-15f9-4354-b3ab-a28fe12e701a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((900000, 2381), (900000, 1))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Creating dataframes of X_train & y_train\n",
        "X_train0 = pd.DataFrame(X_train0)\n",
        "y_train0 = pd.DataFrame(y_train0)\n",
        "X_train0.shape, y_train0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC7kBQKBYPDR",
        "outputId": "43233b62-c5c6-44c8-e7ec-bd494dd7e81b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0., -1.,  1.], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Unique labels in the train dataset\n",
        "y_train0[0].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKK07LGiYWg_",
        "outputId": "7e8de377-026b-4ce2-c35b-7308c6503e58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((900000, 2382), (900000, 1))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combining features and lables of train dataset\n",
        "X_train0[2381] = y_train0[0]\n",
        "X_train0.shape, y_train0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D0_rDlsYaBr",
        "outputId": "95bad73d-2d53-491c-bb3c-2e412d8bc6f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0., -1.,  1.], dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checking the presence of unique lables in the combined dataframe\n",
        "X_train0[2381].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qAjbgPNm-XUT"
      },
      "outputs": [],
      "source": [
        "#dropping unlabeled samples\n",
        "X_train0.drop(X_train0[(X_train0[2381] == -1)].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0M_9rUl9frlw"
      },
      "outputs": [],
      "source": [
        "y_train0.drop(y_train0[(y_train0[0] == -1)].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuQbZCZAYwNR",
        "outputId": "6dafeee6-aecd-4d9a-b94d-30f56da3cf1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((600000, 2382), (600000, 1))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train0.shape, y_train0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob_SYDnEYw8J",
        "outputId": "702567bf-a4ab-4b32-ab93-1a68830ab7cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((600000, 2381), (600000, 1))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#reconstructing the X_train dataframe\n",
        "X_train0.drop([2381], axis =1, inplace=True)\n",
        "X_train0.shape, y_train0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_6fBhDGGYzgC"
      },
      "outputs": [],
      "source": [
        "#Pickling the datasets\n",
        "pd.DataFrame(X_train0).to_pickle(\"./X_train.pkl\")\n",
        "pd.DataFrame(y_train0).to_pickle(\"./y_train.pkl\")\n",
        "pd.DataFrame(X_test0).to_pickle(\"./X_test.pkl\")\n",
        "pd.DataFrame(y_test0).to_pickle(\"./y_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iy8h1sI-vlCm"
      },
      "outputs": [],
      "source": [
        "# Extracting training data from pickle files\n",
        "X_trainp = pd.read_pickle(\"C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\X_train.pkl\")\n",
        "y_trainp = pd.read_pickle(\"C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\y_train.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7FhSwDO-0AfU"
      },
      "outputs": [],
      "source": [
        "# Extracting testing data from pickle files\n",
        "X_testp =pd.read_pickle(\"C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\X_test.pkl\")\n",
        "y_testp = pd.read_pickle(\"C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\y_test.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g2eG5oJn0JM6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((600000, 2381), (600000, 1), (200000, 2381), (200000, 1))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Shape of the dataset\n",
        "X_trainp.shape, y_trainp.shape, X_testp.shape, y_testp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "# Loading X_train data to HDF5 file\n",
        "h50 = h5py.File('X_train0.h5', 'a')\n",
        "h50.create_dataset('X_train0', data=X_train0)\n",
        "h50.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kG7j2GM01ami"
      },
      "outputs": [],
      "source": [
        "# Loading y_train data to HDF5 file\n",
        "h51 = h5py.File('y_train0.h5', 'w')\n",
        "h51.create_dataset('y_train0', data=y_train0)\n",
        "h51.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z2T50QIa1dEd"
      },
      "outputs": [],
      "source": [
        "#Loading X_test data to HDF5 file\n",
        "h52 = h5py.File('X_test0.h5', 'w')\n",
        "h52.create_dataset('X_test0', data=X_test0)\n",
        "h52.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uECdBv3A1fHL"
      },
      "outputs": [],
      "source": [
        "#Loading y_test data to HDF5 file\n",
        "h53 = h5py.File('y_test0.h5', 'w')\n",
        "h53.create_dataset('y_test0', data=y_test0)\n",
        "h53.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_pyzOrDl1kXn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600000, 2381)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#reading the X_train data from h5 files\n",
        "import h5py\n",
        "Xh5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\X_train0.h5','r')\n",
        "X_train = Xh5['X_train0']\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "reRPcvME1nLT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600000, 1)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading y_train data from h5 files\n",
        "import h5py\n",
        "yh5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\y_train0.h5','r')\n",
        "y_train = yh5['y_train0']\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3uc757qN1qFh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000, 2381)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading X_test data from h5 files\n",
        "import h5py\n",
        "Xth5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\X_test0.h5','r')\n",
        "X_test = Xth5['X_test0']\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-BXYUUUS1s7T"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000,)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading y_test data from h5 files\n",
        "import h5py\n",
        "yth5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\y_test0.h5','r')\n",
        "y_test = yth5['y_test0']\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HiesDZ6G4J4j"
      },
      "outputs": [],
      "source": [
        "# Scaling the features inorder to improve the performance of the model\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "rs = RobustScaler()\n",
        "Xtrain_rs = rs.fit_transform(X_train)\n",
        "Xtest_rs = rs.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kFMWZj1-4Ohl"
      },
      "outputs": [],
      "source": [
        "#Loading scaled X_train data to HDF5 file\n",
        "h54 = h5py.File('Xtrain_rs.h5', 'w')\n",
        "h54.create_dataset('Xtrain_rs', data=Xtrain_rs)\n",
        "h54.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "J7-J6KNS4PWp"
      },
      "outputs": [],
      "source": [
        "#Loading scaled X_test data to HDF5 file\n",
        "h55 = h5py.File('Xtest_rs.h5', 'w')\n",
        "h55.create_dataset('Xtest_rs', data=Xtest_rs)\n",
        "h55.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ncSzsfDK4Soy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600000, 2381)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading Xtrain_rs data from h5 files\n",
        "import h5py\n",
        "Xrsh5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\Xtrain_rs.h5','r')\n",
        "Xtrain_rs = Xrsh5['Xtrain_rs']\n",
        "Xtrain_rs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0KmtI8HV4VKw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000, 2381)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading Xtest_rs data from h5 files\n",
        "import h5py\n",
        "Xtrsh5 = h5py.File('C:\\\\Users\\mshee\\OneDrive\\Desktop\\proo\\Xtest_rs.h5','r')\n",
        "Xtest_rs = Xtrsh5['Xtest_rs']\n",
        "Xtest_rs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "Xtrain_rs = np.array(Xtrain_rs)\n",
        "y_train = np.array(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Function for the model\n",
        "# def myModel():\n",
        "\n",
        "#     import tensorflow as tf\n",
        "#     from tensorflow import keras\n",
        "#     from tensorflow.keras import layers\n",
        "#     from tensorflow.keras.models import Sequential\n",
        "#     from keras import regularizers\n",
        "#     tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "#     #Model architecture\n",
        "#     model = Sequential()\n",
        "#     model.add(layers.InputLayer(input_shape=(2381,)))\n",
        "#     model.add(layers.Dropout(0.2))\n",
        "#     model.add(layers.Dense(units = 1000, activation = tf.nn.relu, activity_regularizer=regularizers.l2(0.01)))\n",
        "#     model.add(layers.Dropout(0.5))\n",
        "#     model.add(layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
        "#     print(model.summary())\n",
        "\n",
        "#     #model compilation\n",
        "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#     model.save('my_model.h5')\n",
        "\n",
        "#    return model\n",
        "def myModel():\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import InputLayer, Dense, Dropout, BatchNormalization\n",
        "    from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "\n",
        "    # Model architecture\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(2381,)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1000, activation=tf.nn.sigmoid, activity_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=512, activation=tf.nn.sigmoid))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=256, activation=tf.nn.sigmoid))\n",
        "    model.add(Dense(units=1, activation=tf.nn.sigmoid))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = myModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 119s 62ms/step - loss: 1.6602 - accuracy: 0.5711 - val_loss: 1.1480 - val_accuracy: 0.4458\n"
          ]
        }
      ],
      "source": [
        "#Training the model on 1 epoch\n",
        "history = model.fit(Xtrain_rs, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=1,\n",
        "                validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 1.1941 - accuracy: 0.5958 - val_loss: 1.0667 - val_accuracy: 0.5590\n",
            "Epoch 2/19\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 1.1376 - accuracy: 0.6006 - val_loss: 1.0064 - val_accuracy: 0.6023\n",
            "Epoch 3/19\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 1.0910 - accuracy: 0.6055 - val_loss: 0.9895 - val_accuracy: 0.5025\n",
            "Epoch 4/19\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 1.0769 - accuracy: 0.6095 - val_loss: 0.9757 - val_accuracy: 0.5143\n",
            "Epoch 5/19\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 1.0557 - accuracy: 0.6138 - val_loss: 0.9846 - val_accuracy: 0.4176\n",
            "Epoch 6/19\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 1.0327 - accuracy: 0.6166 - val_loss: 0.9687 - val_accuracy: 0.5406\n",
            "Epoch 7/19\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 1.0115 - accuracy: 0.6176 - val_loss: 0.9349 - val_accuracy: 0.5256\n",
            "Epoch 8/19\n",
            "1875/1875 [==============================] - 108s 57ms/step - loss: 1.0025 - accuracy: 0.6203 - val_loss: 0.9319 - val_accuracy: 0.5470\n",
            "Epoch 9/19\n",
            "1875/1875 [==============================] - 103s 55ms/step - loss: 0.9919 - accuracy: 0.6204 - val_loss: 0.9346 - val_accuracy: 0.5311\n",
            "Epoch 10/19\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.9868 - accuracy: 0.6215 - val_loss: 0.9170 - val_accuracy: 0.5540\n",
            "Epoch 11/19\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.9816 - accuracy: 0.6212 - val_loss: 0.9661 - val_accuracy: 0.4388\n",
            "Epoch 12/19\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.9736 - accuracy: 0.6234 - val_loss: 0.8927 - val_accuracy: 0.5470\n",
            "Epoch 13/19\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.9629 - accuracy: 0.6256 - val_loss: 0.8971 - val_accuracy: 0.5680\n",
            "Epoch 14/19\n",
            "1875/1875 [==============================] - 102s 55ms/step - loss: 0.9505 - accuracy: 0.6278 - val_loss: 0.8912 - val_accuracy: 0.5362\n",
            "Epoch 15/19\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.9463 - accuracy: 0.6279 - val_loss: 0.8967 - val_accuracy: 0.5473\n",
            "Epoch 16/19\n",
            "1875/1875 [==============================] - 1861s 993ms/step - loss: 0.9436 - accuracy: 0.6278 - val_loss: 0.9040 - val_accuracy: 0.4487\n",
            "Epoch 17/19\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.9444 - accuracy: 0.6288 - val_loss: 0.9248 - val_accuracy: 0.4438\n",
            "Epoch 18/19\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.9369 - accuracy: 0.6279 - val_loss: 0.8931 - val_accuracy: 0.4995\n",
            "Epoch 19/19\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.9289 - accuracy: 0.6291 - val_loss: 0.8735 - val_accuracy: 0.5371\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(Xtrain_rs, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=19,\n",
        "                validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# testing the model\n",
        "\n",
        "score =model.evaluate(Xtest_rs,y_test)\n",
        "print(\"Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('model.h5')\n",
        "model.save_weights('model_weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save neural network structure to JSON (no weights)\n",
        "model_json = model.to_json()\n",
        "with open(\"mymodeljson.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model-weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'Anaconda3-2020.02-Windows-x86_64.exe' downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://repo.anaconda.com/archive/Anaconda3-2020.02-Windows-x86_64.exe'\n",
        "file_name = 'Anaconda3-2020.02-Windows-x86_64.exe'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"File '{file_name}' downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to download the file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ember"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testPE(pe):\n",
        "  import ember\n",
        "  import numpy as np\n",
        "  import tensorflow as tf\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "  rs = RobustScaler()\n",
        "\n",
        "  #opening the downloaded PE file\n",
        "  testpe = open(pe, \"rb\").read()\n",
        "  #Feature extractor class of the ember project\n",
        "  extract = ember.PEFeatureExtractor()\n",
        "  data = extract.feature_vector(testpe) #vectorizing the extracted features\n",
        "  scaled_data = rs.fit_transform([data])\n",
        "  Xdata = np.reshape(scaled_data,(1, 2381))\n",
        "\n",
        "  model = tf.keras.models.load_model('my_model.h5')\n",
        "  pred_probabilities = model.predict(Xdata)\n",
        "  pred_classes = np.argmax(pred_probabilities, axis=1)\n",
        "\n",
        "  if pred_classes == 0:\n",
        "        return \"benign\"\n",
        "  elif pred_classes == 1:\n",
        "        return \"malware\"\n",
        "  #return pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\mshee\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "WARNING:tensorflow:From C:\\Users\\mshee\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\mshee\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1/1 [==============================] - 0s 232ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testPE(\"Anaconda3-2020.02-Windows-x86_64.exe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "1/1 [==============================] - 0s 163ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testPE(\"Git-2.43.0-64-bit.exe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int64)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testPE(\"GrammarlyInstaller.cVWGUea8qwif8kgejq0p01o2.exe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
